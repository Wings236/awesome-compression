{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNI剪枝实践\n",
    "\n",
    "模型剪枝是一种通过减少模型权重大小或中间状态大小来减少模型大小和计算量的技术。修剪 DNN 模型有以下三种常见做法：\n",
    "- 预训练模型 -> 修剪模型 -> 微调修剪后的模型\n",
    "- 在训练期间修剪模型（即修剪感知训练）-> 微调修剪后的模型\n",
    "- 修剪模型 -> 从头开始​​训练修剪后的模型\n",
    "\n",
    "NNI支持上述所有的方式，本节以第一种方法为例来展示NNI的用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 参考文档：https://nni.readthedocs.io/zh/stable/tutorials/pruning_quick_start.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcd038a0670>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载ch02中训练好的model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置归一化\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# 获取数据集\n",
    "train_dataset = datasets.MNIST(root='../../ch02/data/mnist', train=True, download=True, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root='../../ch02/data/mnist', train=False, download=True, transform=transform)  # train=True训练集，=False测试集\n",
    "\n",
    "# 设置DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个LeNet网络\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  callbacks = None\n",
    ") -> None:\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    # print(inputs.shape)\n",
    "    # Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward inference\n",
    "    outputs = model(inputs).cpu()\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update optimizer \n",
    "    optimizer.step()\n",
    "\n",
    "    if callbacks is not None:\n",
    "        for callback in callbacks:\n",
    "            callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  verbose=True,\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False,\n",
    "                              disable=not verbose):\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "  \n",
    "    # Inference\n",
    "    outputs = model(inputs).cpu()\n",
    "\n",
    "    # Convert logits to class indices\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 加载参数信息\n",
    "checkpoint = torch.load('../../ch02/model.pt')\n",
    "# 加载状态字典到模型\n",
    "model.load_state_dict(checkpoint)\n",
    "# 查看原始模型结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model paramater number:  44426\n"
     ]
    }
   ],
   "source": [
    "# 查看原始模型参数量\n",
    "print('Original model paramater number: ', sum([param.numel() for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983d0ab0dd784999a3dcb25229172b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has accuracy=97.99%\n"
     ]
    }
   ],
   "source": [
    "# 查看原始模型准确率\n",
    "model_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Model has accuracy={model_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型剪枝\n",
    "使用L1NormPruner减掉80%的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [{\n",
    "    'op_types': ['Linear', 'Conv2d'],\n",
    "    'exclude_op_names': ['fc3'],\n",
    "    'sparse_ratio': 0.8\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(\n",
      "    1, 6, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (_nni_wrapper): ModuleWrapper(module=Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)), module_name=conv1)\n",
      "  )\n",
      "  (conv2): Conv2d(\n",
      "    6, 16, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (_nni_wrapper): ModuleWrapper(module=Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)), module_name=conv2)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(\n",
      "    in_features=256, out_features=120, bias=True\n",
      "    (_nni_wrapper): ModuleWrapper(module=Linear(in_features=256, out_features=120, bias=True), module_name=fc1)\n",
      "  )\n",
      "  (fc2): Linear(\n",
      "    in_features=120, out_features=84, bias=True\n",
      "    (_nni_wrapper): ModuleWrapper(module=Linear(in_features=120, out_features=84, bias=True), module_name=fc2)\n",
      "  )\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from nni.compression.pruning import L1NormPruner\n",
    "pruner = L1NormPruner(model, config_list)\n",
    "\n",
    "# show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2  sparsity :  0.25\n",
      "conv1  sparsity :  0.33\n",
      "fc1  sparsity :  0.2\n",
      "fc2  sparsity :  0.2\n"
     ]
    }
   ],
   "source": [
    "# compress the model and generate the masks\n",
    "_, masks = pruner.compress()\n",
    "# show the masks sparsity\n",
    "for name, mask in masks.items():\n",
    "    print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型加速\n",
    "剪枝算法通常使用权重掩模来模拟真实的剪枝。掩码可用于检查特定修剪（或稀疏性）的模型性能，但没有真正的加速。NNI提供了实际加速功能。\n",
    "为了加速模型，应该替换修剪后的层，或者用较小的层替换粗粒度掩模，或者用稀疏内核替换细粒度掩模。粗粒度掩模通常会改变权重或输入/输出张量的形状，因此，NNI利用形状推断来检查是否有其他未修剪的层也应该由于形状变化而被替换。因此，在设计中，主要有两个步骤：首先，进行形状推断，找出所有应该替换的模块；其次，更换模块。第一步需要模型的拓扑（即连接），NNI使用基于torch.fx的跟踪器来获取 PyTorch 的模型图。模块的新形状是由NNI自动推理的，前向输出和后向输入中未改变的部分准备减少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-23 21:25:34] \u001b[32mStart to speedup the model...\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mResolve the mask conflict before mask propagate...\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mdim0 sparsity: 0.727273\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "0 Filter\n",
      "[2024-09-23 21:25:34] \u001b[32mdim0 sparsity: 0.727273\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mInfer module masks...\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate original variables\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_module: conv1, weight:  0.6667 bias:  0.6667 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_function: relu, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_module: maxpool, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_module: conv2, weight:  0.7500 bias:  0.7500 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_function: relu_1, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_module: maxpool_1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_method: size, \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_function: getitem, \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_method: view, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_module: fc1, weight:  0.8000 bias:  0.8000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_function: relu_2, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_module: fc2, weight:  0.7976 bias:  0.7976 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_function: relu_3, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mPropagate variables for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct sparsity...\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_module: conv1, weight:  0.6667 bias:  0.6667 , output mask:  0.6667 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_function: relu, output mask:  0.6667 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_module: maxpool, , output mask:  0.6667 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_module: conv2, weight:  0.7500 bias:  0.7500 , output mask:  0.7500 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_function: relu_1, output mask:  0.7500 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_module: maxpool_1, , output mask:  0.7500 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_method: size, \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_function: getitem, \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_method: view, output mask:  0.7500 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_module: fc1, weight:  0.8000 bias:  0.8000 , output mask:  0.8000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_function: relu_2, output mask:  0.8000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_module: fc2, weight:  0.7976 bias:  0.7976 , output mask:  0.7976 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_function: relu_3, output mask:  0.7976 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate direct mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect sparsity...\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_function: relu_3, output mask:  0.7976 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_module: fc2, weight:  0.9595 bias:  0.7976 , output mask:  0.7976 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_function: relu_2, output mask:  0.8000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_module: fc1, weight:  0.9500 bias:  0.8000 , output mask:  0.8000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_method: view, output mask:  0.7500 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_function: getitem, \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_method: size, \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_module: maxpool_1, , output mask:  0.7500 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_function: relu_1, output mask:  0.7734 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_module: conv2, weight:  0.9167 bias:  0.7500 , output mask:  0.7734 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_module: maxpool, , output mask:  0.6667 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_function: relu, output mask:  0.7028 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for call_module: conv1, weight:  0.6667 bias:  0.6667 , output mask:  0.7028 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mUpdate indirect mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mResolve the mask conflict after mask propagate...\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mdim0 sparsity: 0.727273\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mdim1 sparsity: 0.571429\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "0 Filter\n",
      "[2024-09-23 21:25:34] \u001b[32mdim0 sparsity: 0.727273\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mdim1 sparsity: 0.571429\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mReplace compressed modules...\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace conv2d with in_channels: 1, out_channels: 2\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace module (name: maxpool, op_type: MaxPool2d)\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace conv2d with in_channels: 2, out_channels: 4\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace linear with new in_features: 64, out_features: 24\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace linear with new in_features: 24, out_features: 17\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace module (name: fc3, op_type: Linear)\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mreplace linear with new in_features: 17, out_features: 10\u001b[0m\n",
      "[2024-09-23 21:25:34] \u001b[32mSpeedup done.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(2, 4, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=24, bias=True)\n",
       "  (fc2): Linear(in_features=24, out_features=17, bias=True)\n",
       "  (fc3): Linear(in_features=17, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to unwrap the model, if the model is wrapped before speedup\n",
    "pruner.unwrap_model()\n",
    "\n",
    "# speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
    "from nni.compression.speedup import ModelSpeedup\n",
    "\n",
    "ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(2, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=24, bias=True)\n",
      "  (fc2): Linear(in_features=24, out_features=17, bias=True)\n",
      "  (fc3): Linear(in_features=17, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 查看裁剪后的模型结构，对比裁剪前后的不同\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model paramater number:  2421\n"
     ]
    }
   ],
   "source": [
    "# 查看裁剪后的模型参数\n",
    "print('Pruned model paramater number: ', sum([param.numel() for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4b6110d7a54803922a66795bf992d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has accuracy=30.50%\n"
     ]
    }
   ],
   "source": [
    "# 查看裁剪后的模型准确率\n",
    "model_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Model has accuracy={model_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa870719416247948b3a97ce14cd3504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745e4ef71be2400384401d83492a1888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Accuracy 94.66% / Best Accuracy: 94.66%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e6d4b9d5664abfbbd0263909457103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0443c73516d44a1f808052c41462d2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Accuracy 96.36% / Best Accuracy: 96.36%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e3d55991f5448abfd5e1ef057a7f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cbf88aec94455c9401d1f4fcf76929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Accuracy 97.05% / Best Accuracy: 97.05%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58ae56f5e314ae2814c25f82b8b027d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d434bc91ef3e494b9ef0be49ed1af839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Accuracy 96.16% / Best Accuracy: 97.05%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4e7855f8824f9d939a3ad96031e89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413aa246381848fcae4b3c4cc680a1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Accuracy 97.25% / Best Accuracy: 97.25%\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "num_epoch = 5\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),  lr=lr, momentum=momentum)  # lr学习率，momentum冲量\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失\n",
    "\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    train(model, train_loader, criterion, optimizer)\n",
    "    accuracy = evaluate(model, test_loader)\n",
    "    is_best = accuracy > best_accuracy\n",
    "    if is_best:\n",
    "        best_accuracy = accuracy       \n",
    "    print(f'Epoch{epoch+1:>2d} Accuracy {accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(2, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=24, bias=True)\n",
      "  (fc2): Linear(in_features=24, out_features=17, bias=True)\n",
      "  (fc3): Linear(in_features=17, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 查看微调后模型的结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning  model paramater number:  2421\n"
     ]
    }
   ],
   "source": [
    "# 查看微调后的模型参数\n",
    "print('Fine-tuning  model paramater number: ', sum([param.numel() for param in model.parameters()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
